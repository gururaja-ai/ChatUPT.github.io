{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1uF-gr7ECi2igrRBFjo5As9fx3AmjJI_0",
      "authorship_tag": "ABX9TyOUGs37Se+XBcwVjCW7V3oZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gururaja-ai/ChatUPT.github.io/blob/master/LSTM%2BGRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rzKgMpap1E0F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries & Data Preprocessing"
      ],
      "metadata": {
        "id": "kswe7_zH6z4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, GRU\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "metadata": {
        "id": "5_H3nE6GJTjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0b5fwehvoxr"
      },
      "outputs": [],
      "source": [
        "# Read the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Deep_Learning_Project/train.csv')\n",
        "\n",
        "# Display the dataset\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing and feature engineering\n",
        "pcu_values = {\n",
        "    \"CAR\": 1,\n",
        "    \"LCV\": 1.5,\n",
        "    \"BUS\": 3,\n",
        "    \"TRUCK\": 3,\n",
        "    \"MAV\": 4.5\n",
        "}\n",
        "\n",
        "df['PCU'] = df['CAR'] * pcu_values['CAR'] + \\\n",
        "            df['LCV'] * pcu_values['LCV'] + \\\n",
        "            df['BUS'] * pcu_values['BUS'] + \\\n",
        "            df['TRUCK'] * pcu_values['TRUCK'] + \\\n",
        "            df['MAV'] * pcu_values['MAV']\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
        "\n",
        "# Calculate the number of days in each month\n",
        "days_in_month = df['Date'].dt.days_in_month\n",
        "# Calculate average daily PCU (ADT)\n",
        "df['ADT'] = df['PCU'] / days_in_month\n",
        "df['Date'] = df['Date'].dt.strftime('%Y-%m')\n",
        "\n",
        "numeric_columns = ['CAR', 'LCV', 'BUS', 'TRUCK', 'MAV','PCU']\n",
        "# Convert numeric columns to integers\n",
        "df[numeric_columns + ['ADT']] = df[numeric_columns + ['ADT']].astype(int)\n",
        "\n",
        "# Display the preprocessed dataset\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "id": "kM7b_vAPwmwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the date and ADT values in a line chart\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(df['Date'], df['ADT'], color='blue')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('ADT')\n",
        "plt.title('Average Daily Traffic (in PCU) over Time')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fhJ4EUJmwzmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "# Define the number of splits (here, we'll use 2 for training and testing)\n",
        "n_splits = 2\n",
        "\n",
        "# Initialize TimeSeriesSplit\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# Initialize lists to store train and test data\n",
        "train_data_list = []\n",
        "test_data_list = []\n",
        "\n",
        "# Split the data using TimeSeriesSplit\n",
        "for train_index, test_index in tscv.split(df):\n",
        "    train_data_list.append(df.iloc[train_index])\n",
        "    test_data_list.append(df.iloc[test_index])\n",
        "\n",
        "# Concatenate the train and test data from all splits\n",
        "train_data = pd.concat(train_data_list)\n",
        "test_data = pd.concat(test_data_list)\n",
        "\n",
        "# Save the training and testing data to CSV files\n",
        "train_data[['Date', 'ADT']].to_csv('train_data.csv', index=False)\n",
        "test_data[['Date', 'ADT']].to_csv('test_data.csv', index=False)\n",
        "\n",
        "# Display the shape of the datasets\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Test data shape:\", test_data.shape)\n"
      ],
      "metadata": {
        "id": "-_iq8RVx7Wdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the last date in the test data\n",
        "last_date = test_data['Date'].max()\n",
        "\n",
        "# Convert the 'Date' column to datetime format\n",
        "test_data['Date'] = pd.to_datetime(test_data['Date'])\n",
        "\n",
        "# Calculate the start date for forecasting by adding one month to the last date\n",
        "start_date = pd.to_datetime(last_date) + pd.DateOffset(months=1)\n",
        "\n",
        "# Define the number of forecasted periods\n",
        "num_periods = 36\n",
        "\n",
        "# Generate forecasted months\n",
        "forecast_months = pd.date_range(start=start_date, periods=num_periods, freq='MS')\n",
        "\n",
        "# Create DataFrame with forecasted months\n",
        "forecast_df = pd.DataFrame({'Date': forecast_months.strftime('%Y-%m'), 'ADT': [None] * num_periods})\n",
        "\n",
        "# Save the forecast data to a CSV file\n",
        "forecast_df.to_csv('forecasted_months.csv', index=False)\n",
        "\n",
        "# Display the forecasted dataframe\n",
        "print(forecast_df.head())"
      ],
      "metadata": {
        "id": "uL1V6uAwxHh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "scaler = MinMaxScaler()\n",
        "train_data_scaled = scaler.fit_transform(train_data[['ADT']])\n",
        "test_data_scaled = scaler.transform(test_data[['ADT']])\n",
        "\n",
        "# Display the scaled training data\n",
        "print(train_data_scaled[:5])\n"
      ],
      "metadata": {
        "id": "fNPYLuYkw-5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a windowed dataset for the LSTM model\n",
        "def create_dataset(data, window_size):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window_size):\n",
        "        X.append(data[i:(i + window_size)])\n",
        "        y.append(data[i + window_size])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "window_size = 12\n",
        "X_train, y_train = create_dataset(train_data_scaled, window_size)\n",
        "X_test, y_test = create_dataset(test_data_scaled, window_size)\n",
        "\n",
        "# Reshape input to be 3D [samples, timesteps, features]\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
        "\n",
        "# Display the shape of the training and testing data\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "32HrMS8MxUzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Create the LSTM model with modified parameters\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=200, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "model.add(LSTM(units=200))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model with custom learning rate using Adam optimizer\n",
        "custom_optimizer = Adam(lr=0.0001)  # Setting learning rate to 0.0001\n",
        "model.compile(optimizer=custom_optimizer, loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n"
      ],
      "metadata": {
        "id": "ngywXCRZ73HJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DFlyM90Yxb9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecasting ADT for the forecasted months\n",
        "forecast_data_scaled = scaler.transform(forecast_df[['ADT']])\n",
        "forecast_data = []\n",
        "\n",
        "# Seed the last window of training data into the model to forecast future ADT\n",
        "current_batch = train_data_scaled[-window_size:].reshape((1, window_size, 1))\n",
        "\n",
        "for i in range(num_periods):\n",
        "    # Predict the next value\n",
        "    forecast = model.predict(current_batch)[0]\n",
        "\n",
        "    # Append the forecasted value to the forecast data\n",
        "    forecast_data.append(forecast)\n",
        "\n",
        "    # Update the current batch to include the forecasted value\n",
        "    current_batch = np.append(current_batch[:,1:,:],[[forecast]],axis=1)\n",
        "\n",
        "# Inverse scaling on forecasted data\n",
        "forecast_data = scaler.inverse_transform(forecast_data)\n",
        "\n",
        "# Update the forecasted ADT in the forecast dataframe\n",
        "forecast_df['ADT'] = forecast_data\n",
        "\n",
        "# Save the updated forecast data to a CSV file\n",
        "forecast_df.to_csv('forecasted_months.csv', index=False)\n",
        "\n",
        "# Display the forecasted dataframe\n",
        "print(forecast_df.head())\n"
      ],
      "metadata": {
        "id": "gCnC0zj-xnhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "\n",
        "# Create the GRU model\n",
        "model_gru = Sequential()\n",
        "model_gru.add(GRU(units=200, input_shape=(X_train.shape[1], 1)))\n",
        "model_gru.add(Dense(units=5))\n",
        "\n",
        "# Compile the GRU model\n",
        "model_gru.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the GRU model\n",
        "history_gru = model_gru.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n"
      ],
      "metadata": {
        "id": "3P1VFXZPxrCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Cuf3D0P-z_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecasting ADT for the forecasted months using GRU\n",
        "forecast_data_gru = []\n",
        "\n",
        "# Seed the last window of training data into the GRU model to forecast future ADT\n",
        "current_batch_gru = train_data_scaled[-window_size:].reshape((1, window_size, 1))\n",
        "\n",
        "for i in range(num_periods):\n",
        "    # Predict the next value using GRU model\n",
        "    forecast_gru = model_gru.predict(current_batch_gru)[0]\n",
        "\n",
        "    # Append the forecasted value to the forecast data\n",
        "    forecast_data_gru.append(forecast_gru)\n",
        "\n",
        "    # Update the current batch to include the forecasted value\n",
        "    current_batch_gru = np.append(current_batch_gru[:,1:,:],[[forecast_gru]],axis=1)\n",
        "\n",
        "# Inverse scaling on forecasted data using GRU model\n",
        "forecast_data_gru = scaler.inverse_transform(forecast_data_gru)\n",
        "\n",
        "# Update the forecasted ADT in the forecast dataframe for GRU\n",
        "forecast_df['ADT_GRU'] = forecast_data_gru\n",
        "\n",
        "# Save the updated forecast data to a new CSV file\n",
        "forecast_df.to_csv('forecasted_months_with_gru.csv', index=False)\n",
        "\n",
        "# Display the forecasted dataframe with GRU\n",
        "print(forecast_df.head())\n"
      ],
      "metadata": {
        "id": "2_aPJ49cyIjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forecast using LSTM\n",
        "forecast_data_lstm = []\n",
        "\n",
        "# Seed the last window of training data into the LSTM model to forecast future ADT\n",
        "current_batch_lstm = train_data_scaled[-window_size:].reshape((1, window_size, 1))\n",
        "\n",
        "for i in range(num_periods):\n",
        "    # Predict the next value using LSTM model\n",
        "    forecast_lstm = model.predict(current_batch_lstm)[0]\n",
        "\n",
        "    # Append the forecasted value to the forecast data\n",
        "    forecast_data_lstm.append(forecast_lstm)\n",
        "\n",
        "    # Update the current batch to include the forecasted value\n",
        "    current_batch_lstm = np.append(current_batch_lstm[:,1:,:],[[forecast_lstm]],axis=1)\n",
        "\n",
        "# Inverse scaling on forecasted data using LSTM model\n",
        "forecast_data_lstm = scaler.inverse_transform(forecast_data_lstm)\n",
        "\n",
        "# Update the forecasted ADT in the forecast dataframe for LSTM\n",
        "forecast_df['ADT_LSTM'] = forecast_data_lstm"
      ],
      "metadata": {
        "id": "mDJNBSFHy422"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure that num_periods matches the length of the forecasted data\n",
        "num_periods = len(test_data)\n",
        "\n",
        "# Calculate RMSE for LSTM and GRU forecasts\n",
        "rmse_lstm = sqrt(mean_squared_error(test_data['ADT'].values, forecast_data_lstm[:num_periods]))\n",
        "rmse_gru = sqrt(mean_squared_error(test_data['ADT'].values, forecast_data_gru[:num_periods]))\n",
        "\n",
        "print(\"RMSE for LSTM Forecast:\", rmse_lstm)\n",
        "print(\"RMSE for GRU Forecast:\", rmse_gru)\n"
      ],
      "metadata": {
        "id": "5-JVjuqSzeYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score"
      ],
      "metadata": {
        "id": "gZjVNbTy0CDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: other metrics to be evaluated\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) for LSTM and GRU forecasts\n",
        "mae_lstm = mean_absolute_error(test_data['ADT'].values, forecast_data_lstm[:num_periods])\n",
        "mae_gru = mean_absolute_error(test_data['ADT'].values, forecast_data_gru[:num_periods])\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE) for LSTM and GRU forecasts\n",
        "mape_lstm = mean_absolute_percentage_error(test_data['ADT'].values, forecast_data_lstm[:num_periods])\n",
        "mape_gru = mean_absolute_percentage_error(test_data['ADT'].values, forecast_data_gru[:num_periods])\n",
        "\n",
        "# Calculate R2 score for LSTM and GRU forecasts\n",
        "r2_lstm = r2_score(test_data['ADT'].values, forecast_data_lstm[:num_periods])\n",
        "r2_gru = r2_score(test_data['ADT'].values, forecast_data_gru[:num_periods])\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(\"MAE for LSTM Forecast:\", mae_lstm)\n",
        "print(\"MAE for GRU Forecast:\", mae_gru)\n",
        "print(\"MAPE for LSTM Forecast:\", mape_lstm)\n",
        "print(\"MAPE for GRU Forecast:\", mape_gru)\n",
        "print(\"R2 Score for LSTM Forecast:\", r2_lstm)\n",
        "print(\"R2 Score for GRU Forecast:\", r2_gru)\n"
      ],
      "metadata": {
        "id": "V0LJhWNBze2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the training and testing data along with forecasted values for LSTM and GRU\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(train_data['ADT'], label='Training Data')\n",
        "plt.plot(test_data['ADT'], label='Testing Data')\n",
        "plt.plot(forecast_df['ADT_LSTM'], label='LSTM Forecast')\n",
        "plt.plot(forecast_df['ADT_GRU'], label='GRU Forecast')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('ADT')\n",
        "plt.title('LSTM and GRU Forecasts vs. Actual Data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot the forecasted values for LSTM and GRU\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(forecast_df['ADT_LSTM'], label='LSTM Forecast')\n",
        "plt.plot(forecast_df['ADT_GRU'], label='GRU Forecast')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('ADT')\n",
        "plt.title('LSTM and GRU Forecasts')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eokyGCu60DEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Define a function to create and compile LSTM model with given hyperparameters\n",
        "def create_lstm_model(units=100, learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    optimizer = Adam(lr=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "best_rmse = float('inf')\n",
        "best_params = {}\n",
        "\n",
        "for units in [50, 100, 150]:\n",
        "    for learning_rate in [0.001, 0.01, 0.1]:\n",
        "        lstm_model = create_lstm_model(units=units, learning_rate=learning_rate)\n",
        "        history = lstm_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=0)\n",
        "        rmse = sqrt(history.history['val_loss'][-1])  # Get RMSE from validation loss\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            best_params['units'] = units\n",
        "            best_params['learning_rate'] = learning_rate\n",
        "\n",
        "print(\"Best LSTM Hyperparameters:\", best_params)\n"
      ],
      "metadata": {
        "id": "AgXLTEta3jAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to create and compile LSTM model with stacked layers\n",
        "def create_stacked_lstm_model(units=150, learning_rate=0.001):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=units, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
        "    model.add(LSTM(units=units, return_sequences=True))\n",
        "    model.add(LSTM(units=units))\n",
        "    model.add(Dense(units=1))\n",
        "\n",
        "    optimizer = Adam(lr=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Train the stacked LSTM model\n",
        "stacked_lstm_model = create_stacked_lstm_model(units=best_params['units'], learning_rate=best_params['learning_rate'])\n",
        "history_stacked_lstm = stacked_lstm_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "43TWKtUp3j87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "QW0bPo7q57sW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'Date' column to string format\n",
        "test_data['Date'] = test_data['Date'].astype(str)\n",
        "\n",
        "# Plot the training and testing data along with forecasted values for LSTM and GRU\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.plot(train_data['Date'], train_data['ADT'], label='Training Data')\n",
        "plt.plot(test_data['Date'], test_data['ADT'], label='Testing Data')\n",
        "plt.plot(forecast_df['Date'], forecast_df['ADT_LSTM'], label='LSTM Forecast')\n",
        "plt.plot(forecast_df['Date'], forecast_df['ADT_GRU'], label='GRU Forecast')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('ADT')\n",
        "plt.title('LSTM and GRU Forecasts vs. Actual Data')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jrdNyk0-57kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion:"
      ],
      "metadata": {
        "id": "iWy-_nSn4sLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Despite multiple iterations and hyperparameter tuning, Model results are not satisfactory as"
      ],
      "metadata": {
        "id": "_YtqM_gi4wY9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDu4QEmt4vqA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}